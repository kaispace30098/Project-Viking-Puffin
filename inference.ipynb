{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOCaeG1ThN00Afs+CfC6m4C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaispace30098/Project-Viking-Puffin/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generating Images with a Custom LoRA**\n",
        "This notebook loads a trained LoRA (Low-Rank Adaptation) file and uses it with the base Stable Diffusion XL model to generate images of a custom character.\n",
        "\n",
        "Goal: Use our trained \"Kaiffin\" LoRA to create new scenes and adventures."
      ],
      "metadata": {
        "id": "IV4_cee1Nav-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access our saved LoRA file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DZtF09kbNgUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 1: Define Configuration\n",
        "\n",
        "Set the paths and the prompt for your image generation.\n",
        "\n",
        "*base_model_id: This must be the same base model the LoRA was trained on (SDXL 1.0).\n",
        "\n",
        "*lora_model_path: Path to the folder containing your final pytorch_lora_weights.safetensors file.\n",
        "\n",
        "*prompt: The creative prompt for the new image. Remember to use your trigger word (\"Kaiffin\")."
      ],
      "metadata": {
        "id": "2hxfUxQ5NjEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "# Path to the FOLDER where the final LoRA is saved\n",
        "lora_model_path = \"/content/drive/MyDrive/MyLoRA/output_lora\"\n",
        "prompt = \"photo of Kaiffin on an icy cliff in Iceland, beautiful lighting, cinematic\"\n",
        "output_image_path = \"/content/drive/MyDrive/MyLoRA/generated_image.png\"\n",
        "# ---------------------"
      ],
      "metadata": {
        "id": "DlutW-ZlNyLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Load Pipeline and Fuse LoRA\n",
        "\n",
        "Here, I load the powerful base SDXL model onto the GPU. Then, we load our small LoRA file and apply its weights to the base model. This effectively \"teaches\" the base model about our custom character just for this session."
      ],
      "metadata": {
        "id": "qLDapb2YN57x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading base SDXL pipeline...\")\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    base_model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "print(f\"Loading LoRA weights from: {lora_model_path}\")\n",
        "pipe.load_lora_weights(lora_model_path)\n",
        "print(\"LoRA weights loaded successfully.\")"
      ],
      "metadata": {
        "id": "AIzxPLukOAfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3: Generate and Save the Image\n",
        "\n",
        "This is the final step where the magic happens. We call the pipeline with our prompt and save the generated image to our Google Drive."
      ],
      "metadata": {
        "id": "Uxtczu7KOGvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Generating image with prompt: '{prompt}'\")\n",
        "image = pipe(\n",
        "    prompt=prompt,\n",
        "    num_inference_steps=35,\n",
        "    guidance_scale=7.5\n",
        ").images[0]\n",
        "\n",
        "print(f\"Saving image to: {output_image_path}\")\n",
        "image.save(output_image_path)\n",
        "\n",
        "print(\"\\n--- Inference Complete ---\")\n",
        "print(\"Please refresh your Google Drive to see the generated image.\")\n",
        "\n",
        "# Display the image in the notebook\n",
        "from IPython.display import Image\n",
        "Image(filename=output_image_path)"
      ],
      "metadata": {
        "id": "09JU3_VoOMHD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}